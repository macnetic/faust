#include "faust_Transform_gpu.h"
namespace Faust
{

	template<>
		int32_t Transform<@FAUST_SCALAR_FOR_GM@,GPU2>::getNbRow() const
		{
			auto marr_funcs = GPUModHandler::get_singleton()->marr_funcs((@FAUST_SCALAR_FOR_GM@)(0));
			if(gpu_mat_arr)
				return marr_funcs->nrows(gpu_mat_arr);
			else
				return -1;
		}

	template<>
		int32_t Transform<@FAUST_SCALAR_FOR_GM@,GPU2>::getNbCol() const
		{
			auto marr_funcs = GPUModHandler::get_singleton()->marr_funcs((@FAUST_SCALAR_FOR_GM@)(0));
			if(gpu_mat_arr)
				return marr_funcs->ncols(gpu_mat_arr);
			else
				return -1;
		}

	template<>
		Transform<@FAUST_SCALAR_FOR_GM@,GPU2>::Transform() : gpu_mat_arr(nullptr), dtor_delete_data(false), dtor_disabled(false), data(std::vector<MatGeneric<@FAUST_SCALAR_FOR_GM@,GPU2>*>())
	{
	}

	template<>
		Transform<@FAUST_SCALAR_FOR_GM@,GPU2>::~Transform()
		{
			auto marr_funcs = GPUModHandler::get_singleton()->marr_funcs((@FAUST_SCALAR_FOR_GM@)(0));
			if(gpu_mat_arr != nullptr)
				marr_funcs->free(this->gpu_mat_arr, /* del mats*/ false); // remove gpu mats individually
			gpu_mat_arr = nullptr;
			if(! this->dtor_disabled)
			{
				for (int i=0;i<data.size();i++)
					if(this->dtor_delete_data)
						delete data[i];
					else
						ref_man.release(data[i]);
			}
		}

	template<>
		void Transform<@FAUST_SCALAR_FOR_GM@,GPU2>::push_back(const MatGeneric<@FAUST_SCALAR_FOR_GM@,GPU2>* M, bool copying/*=true*/, const bool transpose/*=false*/, const bool conjugate/*=false*/)
		{
			auto marr_funcs = GPUModHandler::get_singleton()->marr_funcs((@FAUST_SCALAR_FOR_GM@)(0));
			auto pushed_M = const_cast<MatGeneric<@FAUST_SCALAR_FOR_GM@,GPU2>*>(M);
			if((transpose || conjugate) && !copying)
				throw std::runtime_error("Transform<FPP,GPU2>::push_back(): copying argument must be true if any of transpose or conjugate argument is true.");
			if(copying)
			{
				pushed_M = M->clone();
				if(transpose && conjugate)
					pushed_M->adjoint();
				else if(transpose)
					pushed_M->transpose();
				else if(conjugate)
					pushed_M->conjugate();
			}
			if(gpu_mat_arr == nullptr)
				gpu_mat_arr = marr_funcs->create();
			marr_funcs->addgpu_anymat(gpu_mat_arr, pushed_M->get_gpu_mat_ptr());
			data.push_back(const_cast<MatGeneric<@FAUST_SCALAR_FOR_GM@,GPU2>*>(pushed_M));
			if(!dtor_delete_data) ref_man.acquire(const_cast<MatGeneric<@FAUST_SCALAR_FOR_GM@,GPU2>*>(pushed_M));
		}

	template<>
		int32_t Transform<@FAUST_SCALAR_FOR_GM@,GPU2>::size() const
		{
			auto marr_funcs = GPUModHandler::get_singleton()->marr_funcs((@FAUST_SCALAR_FOR_GM@)(0));
			if(gpu_mat_arr == nullptr) return 0;
			return marr_funcs->size(gpu_mat_arr);
		}

	template<>
		void Transform<@FAUST_SCALAR_FOR_GM@,GPU2>::Display(bool transpose/*=false*/) const
		{
			auto marr_funcs = GPUModHandler::get_singleton()->marr_funcs((@FAUST_SCALAR_FOR_GM@)(0));
			marr_funcs->display_op(gpu_mat_arr, transpose?OP_TRANSP:OP_NOTRANSP);
		}

	template<>
		void Transform<@FAUST_SCALAR_FOR_GM@,GPU2>::replace(const MatGeneric<@FAUST_SCALAR_FOR_GM@, GPU2>* new_mat, const faust_unsigned_int id)
		{
			// update the underlying gpu_mod array
			auto marr_funcs = GPUModHandler::get_singleton()->marr_funcs((@FAUST_SCALAR_FOR_GM@)(0));
			marr_funcs->erase_at(gpu_mat_arr, id, /* free */ false); // the RefManager is responsible to free the GPU matrix
			marr_funcs->insert_anymat(gpu_mat_arr, new_mat->get_gpu_mat_ptr(), id);
			// update local (wrapper) data
			if(dtor_delete_data)
				delete data[id];
			else
				ref_man.release(data[id]);
			data[id] = const_cast<MatGeneric<@FAUST_SCALAR_FOR_GM@,GPU2>*>(new_mat);
			if(! dtor_delete_data)
				ref_man.acquire(data[id]);
			this->update_total_nnz();
		}

	template<>
		void Transform<@FAUST_SCALAR_FOR_GM@, GPU2>::clear()
		{
			auto marr_funcs = GPUModHandler::get_singleton()->marr_funcs((@FAUST_SCALAR_FOR_GM@)(0));
			if(gpu_mat_arr != nullptr)
				marr_funcs->free(this->gpu_mat_arr, /* del mats*/ false);
			for (int i=0;i<data.size();i++)
			{
				if(dtor_delete_data)
					delete data[i];
				else
				{
					ref_man.release(data[i]);
				}
			}
			data.resize(0);
			gpu_mat_arr = marr_funcs->create();
		}

	template<>
		void Transform<@FAUST_SCALAR_FOR_GM@,GPU2>::insert(int32_t id, const MatGeneric<@FAUST_SCALAR_FOR_GM@,GPU2>* M, bool copying/*=true*/)
		{
			auto marr_funcs = GPUModHandler::get_singleton()->marr_funcs((@FAUST_SCALAR_FOR_GM@)(0));
			if(gpu_mat_arr == nullptr)
				gpu_mat_arr = marr_funcs->create();
			auto ins_M = const_cast<MatGeneric<@FAUST_SCALAR_FOR_GM@,GPU2>*>(M);
			if(copying)
				ins_M = M->clone();
			marr_funcs->insert_anymat(gpu_mat_arr, ins_M->get_gpu_mat_ptr(), id);
			data.insert(data.begin()+id, ins_M);
			if(!dtor_delete_data) ref_man.acquire(ins_M);
		}

	template<>
		void Transform<@FAUST_SCALAR_FOR_GM@,GPU2>::erase(int32_t id)
		{
			auto marr_funcs = GPUModHandler::get_singleton()->marr_funcs((@FAUST_SCALAR_FOR_GM@)(0));
			if(gpu_mat_arr != nullptr)
				marr_funcs->remove_mat(gpu_mat_arr, id);
			else
				throw std::runtime_error("gpu_mat_arr is nullptr");
			if(!dtor_delete_data) ref_man.release(*(data.begin()+id));
			data.erase(data.begin()+id);
		}

	template<>
		void Transform<@FAUST_SCALAR_FOR_GM@,GPU2>::transpose()
		{
			auto marr_funcs = GPUModHandler::get_singleton()->marr_funcs((@FAUST_SCALAR_FOR_GM@)(0));
			if(gpu_mat_arr != nullptr)
				marr_funcs->transpose(gpu_mat_arr);
			else
				throw std::runtime_error("gpu_mat_arr is nullptr");
			std::reverse(data.begin(),data.end());
		}

	template<>
		Transform<@FAUST_SCALAR_FOR_GM@,GPU2>::Transform(const std::vector<MatGeneric<@FAUST_SCALAR_FOR_GM@,GPU2>*> &factors, const @FAUST_SCALAR_FOR_GM@ lambda_ /*= (FPP)1.0*/, const bool optimizedCopy/*=false*/, const bool cloning_fact/*=true*/) : Transform()
	{
		//TODO: take optional arguments into account
		GPUModHandler::get_singleton()->check_gpu_mod_loaded();

		auto dsm_funcs = GPUModHandler::get_singleton()->dsm_funcs((@FAUST_SCALAR_FOR_GM@)(0));
		auto marr_funcs = GPUModHandler::get_singleton()->marr_funcs((@FAUST_SCALAR_FOR_GM@)(0));
		auto gp_funcs = GPUModHandler::get_singleton()->gp_funcs();
		gpu_mat_arr = marr_funcs->create();
		for(auto m: factors)
		{
			push_back(m);
		}
	}

	template<>
		std::string Transform<@FAUST_SCALAR_FOR_GM@,GPU2>::to_string(bool transpose/*=false*/) const
		{
			auto marr_funcs = GPUModHandler::get_singleton()->marr_funcs((@FAUST_SCALAR_FOR_GM@)(0));
			const char* cstr = marr_funcs->to_string_op(gpu_mat_arr, transpose?OP_TRANSP:OP_NOTRANSP);
			string out_str(cstr);
			free((void*)cstr);
			return out_str;
		}

	template<>
		void Transform<@FAUST_SCALAR_FOR_GM@,GPU2>::get_product(MatDense<@FAUST_SCALAR_FOR_GM@,GPU2>& M, const char opThis/*='N'*/, const bool isConj/*=false*/) const
		{
			auto marr_funcs = GPUModHandler::get_singleton()->marr_funcs((@FAUST_SCALAR_FOR_GM@)(0));
			auto dsm_funcs = GPUModHandler::get_singleton()->dsm_funcs((@FAUST_SCALAR_FOR_GM@)(0));
			gm_Op op;
			if(opThis == 'N')
				op = OP_NOTRANSP;
			else if(opThis == 'T')
				op = OP_TRANSP;
			else if(opThis == 'H' || opThis == 'T' && isConj)
				op = OP_CONJTRANSP;
			else
				throw std::runtime_error("Invalid opThis");
			auto gpu_mat = marr_funcs->chain_matmul_one(gpu_mat_arr, op);
			if(M.gpu_mat != nullptr)
				dsm_funcs->free(M.gpu_mat);
			//TODO: rather to delete use a marr_funcs function that allows to pass a pre-allocated output buffer
			M.gpu_mat = gpu_mat;
			if(isConj && opThis == 'N') M.conjugate();
		}

	template<>
		faust_unsigned_int Transform<@FAUST_SCALAR_FOR_GM@,GPU2>::get_total_nnz() const
		{
			auto marr_funcs = GPUModHandler::get_singleton()->marr_funcs((@FAUST_SCALAR_FOR_GM@)(0));
			if(gpu_mat_arr == nullptr) throw std::runtime_error("gpu_mat_arr is nullptr");
			return marr_funcs->get_total_nnz(gpu_mat_arr);
		}

	template<>
		void Transform<@FAUST_SCALAR_FOR_GM@,GPU2>::scalarMultiply(const @FAUST_SCALAR_FOR_GM@& alpha)
		{
			auto marr_funcs = GPUModHandler::get_singleton()->marr_funcs((@FAUST_SCALAR_FOR_GM@)(0));
			if(gpu_mat_arr == nullptr) throw std::runtime_error("gpu_mat_arr is nullptr");
			marr_funcs->scalar_mul(gpu_mat_arr, reinterpret_cast<const @GM_SCALAR@*>(&alpha));
		}


	template<>
		Real<@FAUST_SCALAR_FOR_GM@> Transform<@FAUST_SCALAR_FOR_GM@,GPU2>::spectralNorm(int32_t nb_iter_max, float threshold, int& flag)
		{
			auto marr_funcs = GPUModHandler::get_singleton()->marr_funcs((@FAUST_SCALAR_FOR_GM@)(0));
			if(gpu_mat_arr == nullptr) throw std::runtime_error("gpu_mat_arr is nullptr");
			//TODO: update gpu_mod to handle output flag
			return marr_funcs->spectral_norm(gpu_mat_arr, threshold, nb_iter_max);
		}

	template<>
		@FAUST_SCALAR_FOR_GM@ Transform<@FAUST_SCALAR_FOR_GM@,GPU2>::power_iteration(int32_t nb_iter_max, float threshold, int& flag)
		{
			auto marr_funcs = GPUModHandler::get_singleton()->marr_funcs((@FAUST_SCALAR_FOR_GM@)(0));
			if(gpu_mat_arr == nullptr) throw std::runtime_error("gpu_mat_arr is nullptr");
			//TODO: update gpu_mod to handle output flag
			@FAUST_SCALAR_FOR_GM@ lambda;
			marr_funcs->power_iteration(gpu_mat_arr, threshold, nb_iter_max, reinterpret_cast<@GM_SCALAR@*>(&lambda));
			return lambda;
		}

	template<>
		MatDense<@FAUST_SCALAR_FOR_GM@, GPU2> Transform<@FAUST_SCALAR_FOR_GM@,GPU2>::sliceMultiply(const Slice s[2], MatDense<@FAUST_SCALAR_FOR_GM@, GPU2>& gpu_X, const char opThis) const
		{
			auto marr_funcs = GPUModHandler::get_singleton()->marr_funcs((@FAUST_SCALAR_FOR_GM@)(0));
			if(gpu_mat_arr == nullptr) throw std::runtime_error("gpu_mat_arr is nullptr");
			//TODO: refactor this code with other functions doing the same about op
			gm_Op op;
			faust_unsigned_int out_nrows, out_ncols;
			if(opThis == 'N')
			{
				op = OP_NOTRANSP;
				out_nrows = getNbRow();
				out_ncols = getNbCol();
			}
			else if(opThis == 'T')
				op = OP_TRANSP;
			else if(opThis == 'H')
				op = OP_CONJTRANSP;
			else
				throw std::runtime_error("Invalid opThis");
			int rs_size, cs_size;
			if(s[0].start_id != 0 || s[0].end_id != getNbRow())
				rs_size = s[0].end_id-s[0].start_id; // end_id is not included in the slice
			else
				rs_size = 0;
			if(s[1].start_id != 0 || s[1].end_id != getNbRow())
				cs_size = s[1].end_id-s[1].start_id; // end_id is not included in the slice
			else
				cs_size = 0;
			MatDense<@FAUST_SCALAR_FOR_GM@,GPU2> out(out_nrows, out_ncols, nullptr, /*no_alloc*/true);
			// if both cs_size and rs_size are null the following call will call chain_matmul_by_dsm_one
			out.gpu_mat = marr_funcs->sliced_chain_matmul_by_dsm_one(this->gpu_mat_arr, (int) s[0].start_id, (int) rs_size, (int) s[1].start_id, (int) cs_size, op, gpu_X.gpu_mat);
			return out;
		}

	template<>
		MatDense<@FAUST_SCALAR_FOR_GM@, GPU2> Transform<@FAUST_SCALAR_FOR_GM@,GPU2>::indexMultiply(faust_unsigned_int* ids[2], size_t id_lens[2], MatDense<@FAUST_SCALAR_FOR_GM@, GPU2>& gpu_X, const char opThis) const
		{
			auto marr_funcs = GPUModHandler::get_singleton()->marr_funcs((@FAUST_SCALAR_FOR_GM@)(0));
			if(gpu_mat_arr == nullptr) throw std::runtime_error("gpu_mat_arr is nullptr");
			//TODO: refactor this code with other functions doing the same about op
			gm_Op op;
			faust_unsigned_int out_nrows, out_ncols;
			if(opThis == 'N')
			{
				op = OP_NOTRANSP;
				out_nrows = getNbRow();
				out_ncols = getNbCol();
			}
			else if(opThis == 'T')
				op = OP_TRANSP;
			else if(opThis == 'H')
				op = OP_CONJTRANSP;
			else
				throw std::runtime_error("Invalid opThis");

			MatDense<@FAUST_SCALAR_FOR_GM@,GPU2> out(out_nrows, out_ncols, nullptr, /*no_alloc*/true);
			// if both cs_size and rs_size are null the following call will call chain_matmul_by_dsm_one
			//TODO: change ids faust_unsigned_int type to size_t to avoid the casting
			out.gpu_mat = marr_funcs->indexed_chain_matmul_by_dsm_one(this->gpu_mat_arr, (size_t **)ids, id_lens, op, gpu_X.gpu_mat);
			return out;
		}

	template<>
		void Transform<@FAUST_SCALAR_FOR_GM@,GPU2>::multiply(const @FAUST_SCALAR_FOR_GM@& a, const int32_t id/*=-1*/)
		{
			auto marr_funcs = GPUModHandler::get_singleton()->marr_funcs((@FAUST_SCALAR_FOR_GM@)(0));
			marr_funcs->scalar_mul_id(this->gpu_mat_arr, reinterpret_cast<const @GM_SCALAR@*>(&a), id);
		}
}

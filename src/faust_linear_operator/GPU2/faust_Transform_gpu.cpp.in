#include "faust_Transform_gpu.h"
namespace Faust
{

	template<>
		int32_t Transform<@FAUST_SCALAR_FOR_GM@,GPU2>::getNbRow() const
		{
			auto marr_funcs = GPUModHandler::get_singleton()->marr_funcs((@FAUST_SCALAR_FOR_GM@)(0));
			if(gpu_mat_arr)
				return marr_funcs->nrows(gpu_mat_arr);
			else
				return -1;
		}

	template<>
		int32_t Transform<@FAUST_SCALAR_FOR_GM@,GPU2>::getNbCol() const
		{
			auto marr_funcs = GPUModHandler::get_singleton()->marr_funcs((@FAUST_SCALAR_FOR_GM@)(0));
			if(gpu_mat_arr)
				return marr_funcs->ncols(gpu_mat_arr);
			else
				return -1;
		}

	template<>
		Transform<@FAUST_SCALAR_FOR_GM@,GPU2>::Transform() : gpu_mat_arr(nullptr)
	{
	}

	template<>
		Transform<@FAUST_SCALAR_FOR_GM@,GPU2>::~Transform()
		{
			auto marr_funcs = GPUModHandler::get_singleton()->marr_funcs((@FAUST_SCALAR_FOR_GM@)(0));
			if(gpu_mat_arr != nullptr)
				marr_funcs->free(this->gpu_mat_arr, /* del mats*/ true);
			gpu_mat_arr = nullptr;
		}

	template<>
		void Transform<@FAUST_SCALAR_FOR_GM@,GPU2>::push_back(const MatGeneric<@FAUST_SCALAR_FOR_GM@,GPU2>* M, bool copying/*=true*/)
		{
			auto marr_funcs = GPUModHandler::get_singleton()->marr_funcs((@FAUST_SCALAR_FOR_GM@)(0));
			if(gpu_mat_arr == nullptr)
				gpu_mat_arr = marr_funcs->create();
			if(copying)
				marr_funcs->addgpu_anymat(gpu_mat_arr, M->clone()->get_gpu_mat_ptr());
			else
				marr_funcs->addgpu_anymat(gpu_mat_arr, M->get_gpu_mat_ptr());
		}



	template<>
		int32_t Transform<@FAUST_SCALAR_FOR_GM@,GPU2>::size() const
		{
			auto marr_funcs = GPUModHandler::get_singleton()->marr_funcs((@FAUST_SCALAR_FOR_GM@)(0));
			if(gpu_mat_arr == nullptr) return 0;
			return marr_funcs->size(gpu_mat_arr);
		}

	template<>
		MatGeneric<@FAUST_SCALAR_FOR_GM@,GPU2>* Faust::Transform<@FAUST_SCALAR_FOR_GM@,GPU2>::get_fact(int32_t id, bool cloning_fact) const
		{
			auto marr_funcs = GPUModHandler::get_singleton()->marr_funcs((@FAUST_SCALAR_FOR_GM@)(0));
			auto is_sparse = marr_funcs->is_sparse_at(this->gpu_mat_arr, id);
			MatGeneric<@FAUST_SCALAR_FOR_GM@, GPU2>* M = nullptr;
			if(is_sparse)
			{
				M = new MatSparse<@FAUST_SCALAR_FOR_GM@,GPU2>();
				M->set_gpu_mat_ptr(marr_funcs->get_spm(this->gpu_mat_arr, id));
			}
			else
			{
				M = new MatDense<@FAUST_SCALAR_FOR_GM@,GPU2>();
				M->set_gpu_mat_ptr(marr_funcs->get_dsm(this->gpu_mat_arr, id));
			}
			if(cloning_fact)
			{
				auto tmp = M;
				M = M->clone();
				delete tmp;
			}
			return M;
		}

	template<>
		void Transform<@FAUST_SCALAR_FOR_GM@,GPU2>::update(const MatGeneric<@FAUST_SCALAR_FOR_GM@, GPU2>& M, const faust_unsigned_int id)
		{
			auto fact = get_fact(id, false);
			auto fact_type = fact->getType();
			if(M.getType() != fact_type)
				throw std::runtime_error("The factor matrix to update is not of the same type (dense or sparse) as the input matrix.");
			if(fact_type == Dense)
			{
				// fact to update is dense
				auto dfact = dynamic_cast<MatDense<@FAUST_SCALAR_FOR_GM@,GPU2>*>(fact);
				auto dM = dynamic_cast<const MatDense<@FAUST_SCALAR_FOR_GM@,GPU2>*>(&M);
				*dfact = *dM;
			}
			else
			{
				// fact to update is sparse
				auto sfact = dynamic_cast<MatSparse<@FAUST_SCALAR_FOR_GM@,GPU2>*>(fact);
				auto sM = dynamic_cast<const MatSparse<@FAUST_SCALAR_FOR_GM@,GPU2>*>(&M);
				*sfact = *sM;
			}
		}

	template<>
		void Transform<@FAUST_SCALAR_FOR_GM@, GPU2>::get_facts(std::vector<MatGeneric<@FAUST_SCALAR_FOR_GM@,GPU2>*> &factors, bool cloning_facts/*=true*/) const
		{
			for(int i=0;i < size(); i++)
			{
				factors.push_back(get_fact(i, cloning_facts));
			}
		}

	template<>
		void Transform<@FAUST_SCALAR_FOR_GM@, GPU2>::clear()
		{
			auto marr_funcs = GPUModHandler::get_singleton()->marr_funcs((@FAUST_SCALAR_FOR_GM@)(0));
			if(gpu_mat_arr != nullptr)
				marr_funcs->free(this->gpu_mat_arr, /* del mats*/ true);
			gpu_mat_arr = marr_funcs->create();
		}

	template<>
		void Transform<@FAUST_SCALAR_FOR_GM@, GPU2>::operator=(const Transform<@FAUST_SCALAR_FOR_GM@,GPU2>& t)
		{
			this->clear();
			for(int i=0;i<t.size();i++)
			{
				this->push_back(t.get_fact(i, /*cloning*/false), /*copying*/ true);
			}
		}

	template<>
		Transform<@FAUST_SCALAR_FOR_GM@,GPU2>::Transform(const Transform<@FAUST_SCALAR_FOR_GM@,GPU2> & t) : Transform<@FAUST_SCALAR_FOR_GM@,GPU2>()
	{
		*this = t;
	}



	template<>
		void Transform<@FAUST_SCALAR_FOR_GM@,GPU2>::push_first(const MatGeneric<@FAUST_SCALAR_FOR_GM@,GPU2>* M, bool copying/*=true*/)
		{
			auto marr_funcs = GPUModHandler::get_singleton()->marr_funcs((@FAUST_SCALAR_FOR_GM@)(0));
			if(gpu_mat_arr == nullptr)
				gpu_mat_arr = marr_funcs->create();
			if(copying)
				marr_funcs->insert_anymat(gpu_mat_arr, M->clone()->get_gpu_mat_ptr(), 0);
			else
				marr_funcs->insert_anymat(gpu_mat_arr, M->get_gpu_mat_ptr(), 0);
		}



	template<>
		void Transform<@FAUST_SCALAR_FOR_GM@,GPU2>::pop_front()
		{
			auto marr_funcs = GPUModHandler::get_singleton()->marr_funcs((@FAUST_SCALAR_FOR_GM@)(0));
			if(gpu_mat_arr != nullptr)
				marr_funcs->remove_mat(gpu_mat_arr, 0);
			else
				throw std::runtime_error("gpu_mat_arr is nullptr");
		}

	template<>
		void Transform<@FAUST_SCALAR_FOR_GM@,GPU2>::transpose()
		{
			auto marr_funcs = GPUModHandler::get_singleton()->marr_funcs((@FAUST_SCALAR_FOR_GM@)(0));
			if(gpu_mat_arr != nullptr)
				marr_funcs->transpose(gpu_mat_arr);
			else
				throw std::runtime_error("gpu_mat_arr is nullptr");
		}

	template<>
		void Transform<@FAUST_SCALAR_FOR_GM@,GPU2>::pop_back()
		{
			auto marr_funcs = GPUModHandler::get_singleton()->marr_funcs((@FAUST_SCALAR_FOR_GM@)(0));
			if(gpu_mat_arr != nullptr)
				marr_funcs->remove_mat(gpu_mat_arr, size()-1);
			else
				throw std::runtime_error("gpu_mat_arr is nullptr");
		}

	template<>
		Transform<@FAUST_SCALAR_FOR_GM@,GPU2>::Transform(const std::vector<MatGeneric<@FAUST_SCALAR_FOR_GM@,GPU2>*> &factors) : Transform()
	{
		GPUModHandler::get_singleton()->check_gpu_mod_loaded();

		auto dsm_funcs = GPUModHandler::get_singleton()->dsm_funcs((@FAUST_SCALAR_FOR_GM@)(0));
		auto marr_funcs = GPUModHandler::get_singleton()->marr_funcs((@FAUST_SCALAR_FOR_GM@)(0));
		auto gp_funcs = GPUModHandler::get_singleton()->gp_funcs();
		gpu_mat_arr = marr_funcs->create();
		for(auto m: factors)
		{
			push_back(m);
		}
	}

	template<>
		void Transform<@FAUST_SCALAR_FOR_GM@,GPU2>::Display() const
		{
			auto marr_funcs = GPUModHandler::get_singleton()->marr_funcs((@FAUST_SCALAR_FOR_GM@)(0));
			marr_funcs->display(gpu_mat_arr);
		}



	template<>
		void Transform<@FAUST_SCALAR_FOR_GM@,GPU2>::get_product(MatDense<@FAUST_SCALAR_FOR_GM@,GPU2>& M, const char opThis/*='N'*/, const bool isConj/*=false*/) const
		{
			auto marr_funcs = GPUModHandler::get_singleton()->marr_funcs((@FAUST_SCALAR_FOR_GM@)(0));
			auto dsm_funcs = GPUModHandler::get_singleton()->dsm_funcs((@FAUST_SCALAR_FOR_GM@)(0));
			gm_Op op;
			if(opThis == 'N')
				op = OP_NOTRANSP;
			else if(opThis == 'T')
				op = OP_TRANSP;
			else if(opThis == 'H')
				op = OP_CONJTRANSP;
			else
				throw std::runtime_error("Invalid opThis");
			auto gpu_mat = marr_funcs->chain_matmul_one(gpu_mat_arr, op);
			if(M.gpu_mat != nullptr)
				dsm_funcs->free(M.gpu_mat);
			//TODO: rather to delete use a marr_funcs function that allows to pass a pre-allocated output buffer
			M.gpu_mat = gpu_mat;
			if(isConj && opThis != 'H') M.conjugate();
		}

	template<>
		MatDense<@FAUST_SCALAR_FOR_GM@,GPU2> Transform<@FAUST_SCALAR_FOR_GM@,GPU2>::get_product(const char opThis/*='N'*/, const bool isConj/*=false*/) const
		{
			MatDense<@FAUST_SCALAR_FOR_GM@, GPU2> M;
			this->get_product(M, opThis, isConj);
			return M;
		}

	template<>
		faust_unsigned_int Transform<@FAUST_SCALAR_FOR_GM@,GPU2>::get_total_nnz() const
		{
			auto marr_funcs = GPUModHandler::get_singleton()->marr_funcs((@FAUST_SCALAR_FOR_GM@)(0));
			if(gpu_mat_arr == nullptr) throw std::runtime_error("gpu_mat_arr is nullptr");
			return marr_funcs->get_total_nnz(gpu_mat_arr);
		}

	template<>
		void Transform<@FAUST_SCALAR_FOR_GM@,GPU2>::update_total_nnz() const
		{
			//nothing to do get_total_nnz doesn't use any cache by now
		}

	template<>
		void Transform<@FAUST_SCALAR_FOR_GM@,GPU2>::scalarMultiply(const @FAUST_SCALAR_FOR_GM@& alpha)
		{
			auto marr_funcs = GPUModHandler::get_singleton()->marr_funcs((@FAUST_SCALAR_FOR_GM@)(0));
			if(gpu_mat_arr == nullptr) throw std::runtime_error("gpu_mat_arr is nullptr");
			marr_funcs->scalar_mul(gpu_mat_arr, reinterpret_cast<const @GM_SCALAR@*>(&alpha));
		}


	template<>
		Real<@FAUST_SCALAR_FOR_GM@> Transform<@FAUST_SCALAR_FOR_GM@,GPU2>::spectralNorm(int32_t nb_iter_max, float threshold, int& flag)
		{
			auto marr_funcs = GPUModHandler::get_singleton()->marr_funcs((@FAUST_SCALAR_FOR_GM@)(0));
			if(gpu_mat_arr == nullptr) throw std::runtime_error("gpu_mat_arr is nullptr");
			//TODO: update gpu_mod to handle output flag
			return marr_funcs->spectral_norm(gpu_mat_arr, threshold, nb_iter_max);
		}


	template<>
		void Faust::Transform<@FAUST_SCALAR_FOR_GM@,GPU2>::multiply(const Faust::Transform<@FAUST_SCALAR_FOR_GM@,GPU2> & A)
		{
			if (A.size() != 0)
			{
				if (size() == 0)
				{
					(*this)=A;
				}
				else
				{
					if (getNbCol() != A.getNbRow())
					{
						throw std::runtime_error("Dimensions must agree");
					}
					for (int i=0;i<A.size();i++)
					{
						this->push_back(A.get_fact(i, /*cloning*/ false)); // push_back clones it afterward
					}
				}
			}
		}

	template<>
		void Faust::Transform<@FAUST_SCALAR_FOR_GM@,GPU2>::multiplyLeft(const Faust::Transform<@FAUST_SCALAR_FOR_GM@,GPU2> & A)
		{
			if (A.size() != 0)
			{
				if (size() == 0)
				{
					(*this)=A;
				}
				else
				{
					if (A.getNbCol() != getNbRow())
					{
						throw std::runtime_error("Dimensions must agree");
					}
					for (int i=A.size()-1;i>-1;i--)
					{
						this->push_first(A.get_fact(i, /*cloning*/ false)); // push_back clones it afterward
					}
				}
			}
		}

	template<>
		void Transform<@FAUST_SCALAR_FOR_GM@,GPU2>::multiply(const @FAUST_SCALAR_FOR_GM@& a)
		{
			auto marr_funcs = GPUModHandler::get_singleton()->marr_funcs((@FAUST_SCALAR_FOR_GM@)(0));
			marr_funcs->scalar_mul(this->gpu_mat_arr, reinterpret_cast<const @GM_SCALAR@*>(&a));
		}

	template<>
		bool Faust::Transform<@FAUST_SCALAR_FOR_GM@, GPU2>::is_fact_sparse(int id) const
		{
			return get_fact(id, /*cloning*/ false)->getType() == Sparse;
		}

	template<>
		bool Faust::Transform<@FAUST_SCALAR_FOR_GM@, GPU2>::is_fact_dense(int id) const
		{
			return get_fact(id, /*cloning*/ false)->getType() == Dense;
		}

	template<>
		MatDense<@FAUST_SCALAR_FOR_GM@,GPU2> Transform<@FAUST_SCALAR_FOR_GM@,GPU2>::multiply(const Faust::MatDense<@FAUST_SCALAR_FOR_GM@,GPU2> &A, const char opThis)
		{
			auto marr_funcs = GPUModHandler::get_singleton()->marr_funcs((@FAUST_SCALAR_FOR_GM@)(0));
			gm_Op op;
			if(A.gpu_mat == nullptr)
				throw std::runtime_error("MatDense<@FAUST_SCALAR_FOR_GM@,GPU2> argument is not initialized.");
			if(gpu_mat_arr == nullptr)
				throw std::runtime_error("No factors in Transform.");
			int32_t out_nrows = this->getNbCol(), out_ncols = A.getNbCol(); // transpose/adjoint case
			if(opThis == 'N')
			{
				op = OP_NOTRANSP;
				out_nrows = getNbRow();
				out_ncols = getNbCol();
			}
			else if(opThis == 'T')
				op = OP_TRANSP;
			else if(opThis == 'H')
				op = OP_CONJTRANSP;
			else
				throw std::runtime_error("Invalid opThis");
			MatDense<@FAUST_SCALAR_FOR_GM@,GPU2> out(out_nrows, out_ncols, nullptr, /*no_alloc*/true);
			out.gpu_mat = marr_funcs->chain_matmul_by_dsm_one(this->gpu_mat_arr, op, A.gpu_mat);
			return out;
		}

	template<>
		MatGeneric<@FAUST_SCALAR_FOR_GM@,GPU2>* Transform<@FAUST_SCALAR_FOR_GM@,GPU2>::iterator::operator*() const
		{
			return container.get_fact(index, /*cloning_fact*/ false);
		}

	template<>
		Transform<@FAUST_SCALAR_FOR_GM@,GPU2>::iterator& Transform<@FAUST_SCALAR_FOR_GM@,GPU2>::iterator::operator++()
		{
			index++;
			return *this;
		}

	template<>
		Transform<@FAUST_SCALAR_FOR_GM@,GPU2>::iterator Transform<@FAUST_SCALAR_FOR_GM@,GPU2>::iterator::operator+(int arg)
		{
			iterator copy(*this);
			copy.index = this->index+arg;
			return copy;
		}

	template<>
		Transform<@FAUST_SCALAR_FOR_GM@,GPU2>::iterator Transform<@FAUST_SCALAR_FOR_GM@,GPU2>::iterator::operator-(int arg)
		{
			iterator copy(*this);
			copy.index = this->index-arg;
			return copy;
		}

	template<>
		Transform<@FAUST_SCALAR_FOR_GM@,GPU2>::iterator Transform<@FAUST_SCALAR_FOR_GM@,GPU2>::iterator::operator++(int)
		{
			iterator copy(*this);
			this->index++;
			return copy;
		}

	template<>
		bool Transform<@FAUST_SCALAR_FOR_GM@,GPU2>::iterator::operator<(const Transform<@FAUST_SCALAR_FOR_GM@,GPU2>::iterator& it)
		{
			return this->index < it.index;
		}

	template<>
		Transform<@FAUST_SCALAR_FOR_GM@,GPU2>::iterator::iterator(const Transform<@FAUST_SCALAR_FOR_GM@, GPU2>& container, size_t index) : index(index), container(container)
		{
		}

	template<>
		Transform<@FAUST_SCALAR_FOR_GM@,GPU2>::iterator Transform<@FAUST_SCALAR_FOR_GM@,GPU2>::begin() const
		{
			return Transform<@FAUST_SCALAR_FOR_GM@,GPU2>::iterator(*this, 0);
		}

	template<>
		Transform<@FAUST_SCALAR_FOR_GM@,GPU2>::iterator Transform<@FAUST_SCALAR_FOR_GM@,GPU2>::end() const
		{
			return Transform<@FAUST_SCALAR_FOR_GM@,GPU2>::iterator(*this, size());
		}



}

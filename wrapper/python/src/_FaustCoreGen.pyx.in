def type2dtype(type):
    return np.dtype('float32') if type == 'float' else np.dtype(type)

cdef class FaustCoreGen@TYPE_NAME@@PROC@:

    cdef FaustCoreCy.@CPP_CORE_CLASS@[@TYPE@]* @CORE_OBJ@

    def  __cinit__(self, list_factors=None, alpha=1.0, core=False,
                   optimizedCopy=False):
        cdef int [:] indices # only for csr mat
        cdef int [:] indptr # only for csr mat
        cdef @TYPE@ [:,:] data
        cdef @TYPE@ [:] data1d #only for csr mat factor
        cdef unsigned int nbrow
        cdef unsigned int nbcol
        optimizedCopy=False # TODO: so far the auto-conversion of
        #  factors (for opt. of mul by vec) is not enabled, re-enable it later
        # by getting from constructor set by a call from a Faust constructor
        if(alpha != 1.0):
            print("WARNING: the constructor argument for multiplying the Faust"
                  " by a scalar is DEPRECATED and might not be supported in next"
                  " versions of FAµST.")
        if(list_factors is not None):
            if(match('.*int', repr(list_factors[0].dtype))):
               list_factors[0] = list_factors[0].astype(np.float)
            list_factors[0] *= alpha
            for i,factor in enumerate(list_factors):
                # Faust uses row-major order for sparse matrices
                # and col-major order for dense matrices
                # but libmatio uses col-major order for sparse matrices
                if isinstance(factor, (csc_matrix, coo_matrix)):
                    factor = list_factors[i] = factor.tocsr()
                    #print("FaustCorePy.pyx __cinit__(),toarray() factor:", factor)
                if not isinstance(factor, (np.ndarray, csr_matrix, bsr_matrix)):
                   #print("FaustCorePy.pyx __cinit__(), factor:",factor)
                   raise ValueError("Faust factors must be numpy.ndarray,"
                                    " scipy.sparse.csr_matrix/csc_matrix/coo_matrix/bsr_matrix")
            self.@CORE_OBJ@ = new FaustCoreCy.@CPP_CORE_CLASS@[@TYPE@]()
            for factor in list_factors:
                nbrow=factor.shape[0];
                nbcol=factor.shape[1];
                if isinstance(factor, (csc_matrix, coo_matrix)):
                    #TODO: understand how is it possible to have a csc
                    # mat here and fix it (because it should have been
                    # converted above already)
                    factor = list_factors[i] = factor.tocsr()
                #print('FaustCorePy.pyx type factor=',type(factor))
                #print("FaustCorePy.pyx factor=",factor)
                if isinstance(factor, np.ndarray):
                    data=factor.astype(type2dtype('@TYPE@'),'F')
                    self.@CORE_OBJ@.push_back(&data[0,0], nbrow,
                                                   nbcol, optimizedCopy)
                elif isinstance(factor, sparse.bsr_matrix):
                    bnnz = int(factor.nnz/factor.blocksize[0]/factor.blocksize[1])
                    # reshape data with block transposition (because scipy is
                    # in row-major order and FAµST col-major order)
                    _data = np.empty((bnnz, factor.blocksize[1],
                                      factor.blocksize[0]))
                    for i in range(bnnz):
                        _data[i] = factor.data[i].T
                    data1d = _data.reshape(bnnz*factor.blocksize[0]*factor.blocksize[1]).astype(type2dtype('@TYPE@'))#, 'F')
                    indices=factor.indices.astype(np.int32, 'F')
                    indptr=factor.indptr.astype(np.int32, 'F')
                    self.@CORE_OBJ@.push_back(&data1d[0], &indptr[0],
                                              &indices[0],
                                              nbrow, nbcol,
                                              bnnz,
                                              factor.blocksize[0],
                                              factor.blocksize[1],
                                              optimizedCopy)
                else:
                    #print("FaustCore, factor dims:", nbrow, nbcol)
                    data1d = factor.data.astype(type2dtype('@TYPE@'), 'F')
                    indices=factor.indices.astype(np.int32, 'F')
                    indptr=factor.indptr.astype(np.int32, 'F')
                    self.@CORE_OBJ@.push_back(&data1d[0], &indptr[0],
                                              &indices[0], factor.nnz,
                                              nbrow, nbcol,
                                              optimizedCopy)
        elif(core): # trick to initialize a new @CPP_CORE_CLASS@ from C++ (see
        # transpose, conj and adjoint)
            pass
        #else:
        #TODO: raise error for undefined object here

    def clone(self, *args, **kwargs):
        core = @CORE_CLASS@(core=True)
        core.@CORE_OBJ@ = self.@CORE_OBJ@.clone(-1)
        return core

    def nbytes(self):
        nbytes = self.@CORE_OBJ@.getNBytes();
        return nbytes

    def shape(self):
        cdef unsigned int nbrow = 0
        cdef unsigned int nbcol = 0
        nbrow = self.@CORE_OBJ@.getNbRow();
        nbcol = self.@CORE_OBJ@.getNbCol();
        return (nbrow,nbcol)

    def multiply_csr_mat(self, X):
        cdef int [:] x_indices
        cdef int [:] x_indptr
        cdef @TYPE@ [:] x_data
        cdef @TYPE@ [:,:] y_data
        # X is supposed to be a csr_matrix
        x_indices = X.indices
        x_indptr = X.indptr
        x_nnz = X.nnz
        nbcol = X.shape[1]
        e = Exception("Dimensions must agree")
        x_data = X.data
        nbrow = self.@CORE_OBJ@.getNbRow()
        if(self.@CORE_OBJ@.getNbCol() != X.shape[0]): raise e
        y_data_arr = np.empty((nbrow,nbcol), dtype=np.@TYPE@, order='F') # we don't know beforehand Y nnz
        y_data = y_data_arr
        self.@CORE_OBJ@.multiply(&y_data[0,0], nbrow, nbcol,
                                  &x_data[0], &x_indptr[0],
                                  &x_indices[0],
                                  x_nnz, X.shape[0], X.shape[1])
        return y_data_arr

    def get_product(self):
        cdef @TYPE@[:,:] y_data

        y_arr = np.empty((self.@CORE_OBJ@.getNbRow(), self.@CORE_OBJ@.getNbCol()),
                         dtype=type2dtype('@TYPE@'),
                         order='F')
        y_data = y_arr
        self.@CORE_OBJ@.get_product(&y_data[0,0], y_arr.shape[0],
                                        y_arr.shape[1])
        return y_arr

    def multiply_faust(self, F):
        if isinstance(F, @CORE_CLASS@):
            core = @CORE_CLASS@(core=True)
            if F.isReal() == self.isReal():
                core.@CORE_OBJ@ = \
                        self.@CORE_OBJ@.mul_faust((<@CORE_CLASS@?>F).@CORE_OBJ@)
            else:
                raise ValueError("F and self are not Faust of the same scalar type.")
            return core
        raise ValueError("F must be a Faust object")

    def isReal(self):
        return '@TYPE@' != 'complex'

    def device(self):
        cdef char c_str[256]
        self.@CORE_OBJ@.device(c_str)
        cdef length = strlen(c_str)
        py_str = c_str[:length].decode('UTF-8', 'ignore')
        return py_str

    def multiply_scal(self, scalar):
        # self is supposed to be defined over the same field as scalar
        core = @CORE_CLASS@(core=True)
        core.@CORE_OBJ@ = self.@CORE_OBJ@.mul_scal(scalar)
        return core

    def vertcat(self, F):
        # assume self are defined over the same scalar type
        core = @CORE_CLASS@(core=True)
        core.@CORE_OBJ@ = self.@CORE_OBJ@.vertcat((<@CORE_CLASS@?>F).@CORE_OBJ@)
        return core

    def horzcat(self, F):
        # assume self are defined over the same scalar type
        core = @CORE_CLASS@(core=True)
        core.@CORE_OBJ@ = self.@CORE_OBJ@.horzcat((<@CORE_CLASS@?>F).@CORE_OBJ@)
        return core

    def vertcatn(self, Fs):
        # assume self and all F in Fs are defined over the same scalar type
        cdef FaustCoreCy.@CPP_CORE_CLASS@[@TYPE@]** _Fs

        _Fs = <FaustCoreCy.@CPP_CORE_CLASS@[@TYPE@]**> PyMem_Malloc(sizeof(void*) *
                                                                len(Fs))
        for i, F in enumerate(Fs):
            _Fs[i] = (<@CORE_CLASS@?>F).@CORE_OBJ@

        core = @CORE_CLASS@(core=True)
        core.@CORE_OBJ@ = self.@CORE_OBJ@.vertcatn(_Fs, len(Fs))

        PyMem_Free(_Fs)
        return core

    def horzcatn(self, Fs):
        # assume self and all F in Fs are defined over the same scalar type
        cdef FaustCoreCy.@CPP_CORE_CLASS@[@TYPE@]** _Fs

        _Fs = <FaustCoreCy.@CPP_CORE_CLASS@[@TYPE@]**> PyMem_Malloc(sizeof(void*) *
                                                                len(Fs))
        for i, F in enumerate(Fs):
            _Fs[i] = (<@CORE_CLASS@?>F).@CORE_OBJ@

        core = @CORE_CLASS@(core=True)
        core.@CORE_OBJ@ = self.@CORE_OBJ@.horzcatn(_Fs, len(Fs))

        PyMem_Free(_Fs)
        return core

    def polyCoeffs(self, coeffs):
        core = @CORE_CLASS@(core=True)
        cdef @TYPE@[:] cview
        cview = coeffs
        core.@CORE_OBJ@ = self.@CORE_OBJ@.polyCoeffs(&cview[0])
        return core

    def mulPolyCoeffs(self, coeffs, X, out=None):
        cdef @TYPE@[:] cview
        cdef @TYPE@[:,:] Xview
        cdef @TYPE@[:,:] Yview

        #TODO: all arguments must be of the same scalar type as self

        X_1dim = False
        d = X.shape[0]
        if(X.ndim > 1):
            X = np.asfortranarray(X)
            n = X.shape[1]
        else:
            n = 1
            X = X.reshape(d, 1)
            X_1dim = True

        if not isinstance(out, type(None)):
            Y = out
            if Y.ndim == 1:
                raise ValueError('out must have 2 dimensions.')
            if Y.shape != (d,n):
                raise ValueError('out shape isn\'t valid.')
            dtype_err = ValueError('out dtype isn\'t valid.')
            if not Y.flags['F_CONTIGUOUS']:
                raise ValueError('the array must be in fortran/column continous order.')
            if Y.dtype != type2dtype('@TYPE@'):
                raise dtype_err
            Yview = Y
            Xview = X
            cview = coeffs
        else:
            cview = coeffs
            Y = np.empty((X.shape[0], n), dtype=type2dtype('@TYPE@'), order='F')
            Yview = Y
            Xview = X


        self.@CORE_OBJ@.mulPolyCoeffs(&Xview[0,0],
                                           n,
                                           &Yview[0,0],
                                           &cview[0])
        if X_1dim:
            # X is a vector, Y must be one too
            Y = np.squeeze(Y)

        return Y

    def polyNext(self):
        core = @CORE_CLASS@(core=True)
        core.@CORE_OBJ@ = self.@CORE_OBJ@.polyNext()
        return core

    # Left-Multiplication by a Faust F
    # y=multiply(F,M) is equivalent to y=F*M
    def multiply(self,M):
        if not isinstance(M, np.ndarray):
            raise ValueError('input M must be a numpy.ndarray')
        #TODO: raise exception if not real nor complex

        ndim_M=M.ndim;

        if (ndim_M > 2) | (ndim_M < 1):
            raise ValueError('input M invalid number of dimensions')
        check_matrix(self.isReal(), M)
        ndim_M=M.ndim
        cdef unsigned int nbrow_x=M.shape[0]
        cdef unsigned int nbcol_x #can't be assigned because we don't know yet if the input vector is 1D or 2D

        dimThis=self.shape()
        cdef unsigned int nbRowThis=dimThis[0];
        cdef unsigned int nbColThis=dimThis[1];


        cdef unsigned int nbrow_y=nbRowThis
        cdef unsigned int nbcol_y

        cdef @TYPE@[:] xview_1D
        cdef @TYPE@[:,:] xview_2D

        if ndim_M == 1:
            nbcol_x=1
            xview_1D=M
        else:
            nbcol_x=M.shape[1]
            xview_2D=M

            if (nbrow_x != nbColThis):
                raise ValueError('y=F*M multiplication with Faust: invalid dimension of the input matrix M');

        #void multiply(FPP* value_y,int nbrow_y,int nbcol_y,FPP* value_x,int nbrow_x,int nbcol_x,bool isTranspose);
        nbcol_y = nbcol_x;

        cdef y
        cdef @TYPE@[:,:] yview
        y = np.empty([nbrow_y, nbcol_y], dtype=type2dtype('@TYPE@'), order='F')
        yview = y

        if ndim_M == 1:
            self.@CORE_OBJ@.multiply(&yview[0,0], nbrow_y,
                                          nbcol_y, &xview_1D[0],
                                          nbrow_x,nbcol_x)
            y = np.squeeze(y) # we want a single dim. (but we created two
            # above)
        else:
            self.@CORE_OBJ@.multiply(&yview[0,0],nbrow_y,nbcol_y,&xview_2D[0,0],nbrow_x,nbcol_x)

        return y

    def set_FM_mul_mode(self, mode, silent=True):
        self.@CORE_OBJ@.set_FM_mul_mode(mode, silent)

    # print information about the faust (size, number of factor, type of factor (dense/sparse) ...)
    def display(self):
        self.@CORE_OBJ@.Display()

    def to_string(self):
        cdef const char* c_str
        c_str = self.@CORE_OBJ@.to_string()
        cdef length = strlen(c_str)
        #printf("%s", c_str[:length])
        #py_str = str(c_str[:length], 'UTF-8')
        py_str = c_str[:length].decode('UTF-8', 'ignore')
        free(<void*>c_str)
        return py_str

    def nnz(self):
        cdef unsigned long long nnz = 0
        nnz = self.@CORE_OBJ@.nnz()
        return nnz

    def norm(self, ord, **kwargs):
        cdef double norm
        cdef double threshold
        if(str(ord).lower() not in ["1","2","fro", "inf"]):
            raise ValueError("FaustCorePy.norm() invalid type of norm asked.")
        threshold = .001
        max_num_its = 100
        full_array = True;
        batch_size = 1;
        if 'threshold' in kwargs.keys():
            threshold = kwargs['threshold']
        if 'max_num_its' in kwargs.keys():
            max_num_its = kwargs['max_num_its']
        if 'full_array' in kwargs.keys():
            full_array = kwargs['full_array']
        if 'batch_size' in kwargs.keys():
            batch_size = kwargs['batch_size']
        if ord == 2:
            norm = self.@CORE_OBJ@.norm2(threshold, max_num_its)
        elif ord == np.inf:
            norm = self.@CORE_OBJ@.normInf(full_array, batch_size)
        elif ord == 1:
            norm = self.@CORE_OBJ@.norm1(full_array, batch_size);
        else:
            norm = self.@CORE_OBJ@.normFro(full_array, batch_size)
        return norm


    def power_iteration(self, threshold, max_num_its):
        cdef @TYPE@[:]  _lambda_view
        _lambda = np.empty((1,), dtype=np.complex)
        _lambda_view = _lambda
        self.@CORE_OBJ@.power_iteration(&_lambda_view[0], threshold, max_num_its)
        return _lambda[0]

    def normalize(self, ord):
        core = @CORE_CLASS@(core=True)
        core.@CORE_OBJ@ = self.@CORE_OBJ@.normalize(ord)
        return core

    def get_nb_factors(self):
        cdef int nb_factors
        nb_factors = int(self.@CORE_OBJ@.get_nb_factors())
        return nb_factors

    def is_all_sparse(self, csr, bsr):
        return self.@CORE_OBJ@.is_all_sparse(csr, bsr)

    def is_all_dense(self):
        return self.@CORE_OBJ@.is_all_dense()

    def get_fact(self,i):
        if(i >=  self.get_nb_factors() or i < 0):
            raise ValueError("factor index must be greater or equal 0 and "
                             "lower than "+str(self.get_nb_factors())+".")
        cdef fact
        cdef @TYPE@[:,:] fact_view
        fact = np.empty([self.@CORE_OBJ@.get_fact_nb_rows(i),
                          self.@CORE_OBJ@.get_fact_nb_cols(i)],
                             dtype='complex', order='F')
        fact_view = fact
        self.@CORE_OBJ@.get_fact(i, &fact_view[0, 0])
        return fact

    def get_fact_opt(self, i):
        if(i >=  self.get_nb_factors() or i < 0):
            raise ValueError("factor index must be greater or equal 0 and "
                             "lower than "+str(self.get_nb_factors())+".")
        cdef fact
        cdef @TYPE@[:,:] fact_view
        cdef rowptr, col_ids, elts, nnz
        cdef int[:] rowptr_view, col_ids_view
        ### for bsr matrix buffer
        cdef size_t[:] bsr_sz_view
        cdef @TYPE@[:] bsr_data1d_view
        ###
        #is_fact_sparse = self.@CORE_OBJ@.is_fact_sparse(i)
        fac_type = self.@CORE_OBJ@.get_fact_type(i) # 0 == Dense, 1 == Sparse,
                                                    # 2 == Diag, 3 == BSR
        is_transposed = self.@CORE_OBJ@.isTransposed()
        #print("fac_type:", fac_type)
        if fac_type == 1: # Sparse matrix
            # is_transposed = False # uncomment to disable the trick which
            # uses csc representation instead of csr transpose
            # to optimize copy
            nnz = self.@CORE_OBJ@.get_fact_nnz(i)
            col_ids = np.ndarray([nnz], dtype=np.int32)
            elts = np.ndarray([1,nnz], dtype=type2dtype('@TYPE@'))
            col_ids_view = col_ids
            shape = [self.@CORE_OBJ@.get_fact_nb_rows(i),
             self.@CORE_OBJ@.get_fact_nb_cols(i)]
            if(is_transposed):
                rowptr_sz = shape[1]+1
            else:
                rowptr_sz = shape[0]+1

            rowptr = np.ndarray([rowptr_sz], dtype=np.int32)
            rowptr_view = rowptr
            fact_view = elts
            self.@CORE_OBJ@.get_fact_sparse(i, &rowptr_view[0],
                                                 &col_ids_view[0],
                                                 &fact_view[0,0],
                                                 is_transposed)
            #print("(rowptr)=", (rowptr))
#                print("(col_ids)=", (col_ids))
#                print("(elts[0,:]=", (elts))
            if(is_transposed):
                fact = csc_matrix((elts[0,:], col_ids, rowptr), shape=shape)
            else:
                fact = csr_matrix((elts[0,:], col_ids, rowptr), shape=shape)
        elif fac_type == 0: # dense matrix
            if(is_transposed):
                order = 'C'
                # C contiguous repr. (row-major order ) is used to optimized the
                # request of transpose factor (no need to reorder data as we
                # should in col-major/Fortran repr.)
            else:
                order = 'F'
            fact = np.ndarray([self.@CORE_OBJ@.get_fact_nb_rows(i),
                         self.@CORE_OBJ@.get_fact_nb_cols(i)], dtype=type2dtype('@TYPE@'), order=order)
            fact_view = fact
            self.@CORE_OBJ@.get_fact_dense(i, &fact_view[0, 0],
                                               <unsigned int*>NULL,
                                               <unsigned int*>NULL,
                                               is_transposed)
        elif fac_type == 3: # BSR matrix
            #            print("factor to retrieve is a BSR matrix.")
            nrows = self.@CORE_OBJ@.get_fact_nb_rows(i)
            ncols = self.@CORE_OBJ@.get_fact_nb_cols(i)
            #            print("nrows, ncols:", nrows, ncols)
            nnz = self.@CORE_OBJ@.get_fact_nnz(i)
            buf_sizes = np.empty((6), dtype='uint64') # sizes of bdata, browptr
            # and bcolinds, bnnz, bnrows, bncols
            bsr_sz_view = buf_sizes
            self.@CORE_OBJ@.get_fact_bsr_info(i, bsr_sz_view[0],
                                              bsr_sz_view[1],
                                              bsr_sz_view[2],
                                              bsr_sz_view[3],
                                              bsr_sz_view[4],
                                              bsr_sz_view[5])
            #            print("bsr buf sizes:", buf_sizes, "nnz: ", nnz)
            bsr_data1d = np.empty(buf_sizes[3] * buf_sizes[5] * buf_sizes[4], dtype=type2dtype('@TYPE@'))
            bsr_data1d_view = bsr_data1d
            bsr_data_3d = bsr_data1d.reshape((buf_sizes[3], buf_sizes[5],
                                                buf_sizes[4]))
            browptr = np.empty((buf_sizes[1]), dtype='int32')
            bcolinds = np.empty((buf_sizes[2]), dtype='int32')
            rowptr_view = browptr
            col_ids_view = bcolinds
            self.@CORE_OBJ@.get_fact_bsr(i, &bsr_data1d_view[0], &rowptr_view[0],
                                         &col_ids_view[0])
            bsr_data_3d_T = np.empty((buf_sizes[3], buf_sizes[4],
                                      buf_sizes[5]), dtype=type2dtype('@TYPE@'))
            for i in range(buf_sizes[3]):
                bsr_data_3d_T[i] = bsr_data_3d[i].T
            #            print("bsr_data_3d:", bsr_data_3d)
            #            print("browptr:", browptr)
            #            print("bcolinds:", bcolinds)
            return bsr_matrix((bsr_data_3d_T, bcolinds, browptr), shape=(nrows,
                                                                        ncols))
        return fact

    def slice(self, indices):
        # TODO: rename this function or cut in two: slice and fancy indexing
        core = @CORE_CLASS@(core=True)
        start_row_id, end_row_id, start_col_id, end_col_id = (indices[0].start,
                                                              indices[0].stop,
                                                              indices[1].start,
                                                              indices[1].stop)
        core.@CORE_OBJ@ = self.@CORE_OBJ@.slice(start_row_id,
                                                          end_row_id,
                                                          start_col_id,
                                                          end_col_id)

        return core

    def left(self, id):
        core = @CORE_CLASS@(core=True)
        core.@CORE_OBJ@ = self.@CORE_OBJ@.left(id)
        return core

    def right(self, id):
        core = @CORE_CLASS@(core=True)
        core.@CORE_OBJ@ = self.@CORE_OBJ@.right(id)
        return core

    def fancy_idx(self, indices):
        cdef unsigned long int[:] row_indices_view
        cdef unsigned long int[:] col_indices_view
        core = @CORE_CLASS@(core=True)
        # fancy indexing
        #convert possible slice (on index 0 or 1 of out_indices) to
        # an array of indices
        for i in range(0,2):
            if(isinstance(indices[i], slice)):
               indices[i] = list(range(indices[i].start, indices[i].stop,
                                       indices[i].step))
        # it's possible that on certain architectures unsigned long int is a
        # 4-bytes integer
        # TODO: move to a cross-platform size type (like uint32/64_t from stdlib.h)
        if(sizeof(unsigned long int) == 8):
            dtype = np.uint64
        elif(sizeof(unsigned long int) == 4):
            dtype = np.uint32

        row_indices = np.array(indices[0], dtype=dtype)
        col_indices = np.array(indices[1], dtype=dtype)
        row_indices_view = row_indices
        col_indices_view = col_indices
#        print("FaustCorePy.fancy_idx(), row_indices=", row_indices, " size=",
#              row_indices.size)
#        print("FaustCorePy.fancy_idx(), col_indices=", col_indices," size=",
#              col_indices.size)
        core.@CORE_OBJ@ = \
        self.@CORE_OBJ@.fancy_idx(&row_indices_view[0],
                                       row_indices.size,
                                       &col_indices_view[0],
                                       col_indices.size)

        return core

    def save_mat_file(self,filepath):
        cdef char * cfilepath = <char*> PyMem_Malloc(sizeof(char) *
                                                     (len(filepath)+1))
        fparr = bytearray(filepath, "UTF-8");
        for i in range(0,len(filepath)):
            cfilepath[i] = fparr[i]
        cfilepath[i+1] = 0
        ret = self.@CORE_OBJ@.save_mat_file(cfilepath)
        if(not ret):
            raise Exception("Failed to save the file: "+filepath)
        PyMem_Free(cfilepath)

    @staticmethod
    def read_from_mat_file(filepath):
        cdef char * cfilepath = <char*> PyMem_Malloc(sizeof(char) *
                                                     (len(filepath)+1))
        fparr = bytearray(filepath, "UTF-8");
        for i in range(0,len(filepath)):
            cfilepath[i] = fparr[i]
        cfilepath[i+1] = 0
        core = @CORE_CLASS@(core=True)
        core.@CORE_OBJ@ = FaustCoreCy.@CPP_CORE_CLASS@[@TYPE@].read_from_mat_file(cfilepath)
        PyMem_Free(cfilepath)
        return core

    @staticmethod
    def get_mat_file_type(filepath):
        # TODO: refactor this code with the two methods above
        cdef char * cfilepath = <char*> PyMem_Malloc(sizeof(char) *
                                                     (len(filepath)+1))
        fparr = bytearray(filepath, "UTF-8");
        for i in range(0,len(filepath)):
            cfilepath[i] = fparr[i]
        cfilepath[i+1] = 0
        _type = FaustCoreCy.@CPP_CORE_CLASS@[@TYPE@].get_mat_file_type(cfilepath)
        PyMem_Free(cfilepath)
        return _type


    def transpose(self):
        core = @CORE_CLASS@(core=True)
        core.@CORE_OBJ@ = self.@CORE_OBJ@.transpose()
        return core

    def swap_cols(self, id1, id2, permutation, inplace):
        if(inplace):
            self.@CORE_OBJ@.swap_cols(id1, id2,
                                           permutation,
                                           inplace)

            return self
        core = @CORE_CLASS@(core=True)
        core.@CORE_OBJ@ = self.@CORE_OBJ@.swap_cols(id1, id2,
                                                    permutation,
                                                    inplace)
        return core

    def swap_rows(self, id1, id2, permutation, inplace):
        if(inplace):
            self.@CORE_OBJ@.swap_rows(id1, id2,
                                           permutation,
                                           inplace)

            return self
        core = @CORE_CLASS@(core=True)
        core.@CORE_OBJ@ = self.@CORE_OBJ@.swap_rows(id1, id2,
                                                    permutation,
                                                    inplace)
        return core

    def optimize_storage(self, time=False):
        core = @CORE_CLASS@(core=True)
        core.@CORE_OBJ@ = self.@CORE_OBJ@.optimize_storage(time)
        return core

    def optimize(self, transp=False):
        core = @CORE_CLASS@(core=True)
        core.@CORE_OBJ@ = self.@CORE_OBJ@.optimize(transp)
        return core

    def optimize_time(self, transp=False, inplace=False, nsamples=1, M=None):
        cdef @TYPE@[:,:] M_data
        cdef int [:] M_indices
        cdef int [:] M_indptr
        cdef @TYPE@ [:] M_csr_data

        M_is_dense = False
        if M is None:
            # optimize time according to Faust.toarray()
            if(inplace):
                self.@CORE_OBJ@.optimize_time(transp, inplace, nsamples)
            else:
                core = @CORE_CLASS@(core=True)
                core.@CORE_OBJ@ = self.@CORE_OBJ@.optimize_time(transp,
                                                                inplace,
                                                                nsamples)
                return core
        else:
            # optimize time according to F@M
            if isinstance(M, np.ndarray):
                M_is_dense = True
                M_nrows = M.shape[0]
                M_ncols = M.shape[1]
                M_data = M
            elif isinstance(M, csr_matrix):
                M_nrows = M.shape[0]
                M_ncols = M.shape[1]
                M_csr_data = M.data
                M_indices = M.indices
                M_indptr = M.indptr
                M_nnz = M.nnz
            else:
                 raise TypeError("M must be a np.ndarray or a csr_matrix.")
            if(inplace):
                if M_is_dense:
                    self.@CORE_OBJ@.optimize_time(&M_data[0,0], M_nrows, M_ncols, transp, inplace, nsamples)
                else:
                    self.@CORE_OBJ@.optimize_time(&M_csr_data[0], &M_indptr[0],
                                                  &M_indices[0],
                                                  M_nnz, M_nrows, M_ncols, transp, inplace, nsamples)
            else:
                core = @CORE_CLASS@(core=True)
                if M_is_dense:
                    core.@CORE_OBJ@ = \
                    self.@CORE_OBJ@.optimize_time(&M_data[0,0], M_nrows, M_ncols,
                                                                    transp,
                                                                    inplace,
                                                                    nsamples)
                else:
                    core.@CORE_OBJ@ = \
                    self.@CORE_OBJ@.optimize_time(&M_csr_data[0], &M_indptr[0],
                                                  &M_indices[0],
                                                  M_nnz, M_nrows, M_ncols,
                                                  transp,
                                                  inplace,
                                                  nsamples)
                return core

    def conj(self):
        core = @CORE_CLASS@(core=True)
        core.@CORE_OBJ@ = self.@CORE_OBJ@.conjugate()
        return core

    def getH(self):
        core = @CORE_CLASS@(core=True)
        core.@CORE_OBJ@ = self.@CORE_OBJ@.adjoint()
        return core

    def real(self):
        core = @CORE_CLASS_REAL@(core=True)
        (<@CORE_CLASS_REAL@>core).@CORE_OBJ_REAL@ = \
        <FaustCoreCy.@CPP_CORE_CLASS@[@REAL_TYPE@]*>FaustCoreCy.@CPP_CORE_CLASS@2[@TYPE@,
                                                                                 @REAL_TYPE@].real((<@CORE_CLASS@?>self).@CORE_OBJ@)
        return core

    def dtype(self):
        return type2dtype('@TYPE@')

    def zpruneout(self, nnz_tres, npasses, only_forward):
        core = @CORE_CLASS@(core=True)
        core.@CORE_OBJ@ = self.@CORE_OBJ@.zpruneout(nnz_tres,
                                                    npasses,
                                                    only_forward)
        return core

    def get_item(self, i, j):
        return self.@CORE_OBJ@.get_item(i,j)

    def __dealloc__(self):
        del self.@CORE_OBJ@


{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f8cc8a4",
   "metadata": {},
   "source": [
    "# Using the poly module\n",
    "\n",
    "A new module has been added to pyfaust version 3.0.x. Its name is ``poly`` and as expected it is dedicated to a kind of Fausts that are defined according to polynomials. \n",
    "\n",
    "In this notebook we'll see how to use the main functions of this module then we'll introduce two precise use cases with the action of inverse or exponential matrix on a vector / matrix.\n",
    "\n",
    "**NOTE**: all the functions introduced in this notebook are available \n",
    "\n",
    "## 1. The basis function\n",
    "\n",
    "Firstly, the poly module allows to define a polynomial basis (a ``FaustPoly``) using the function ``pyfaust.poly.basis``. Currently, only Chebyshev polynomials are supported but other are yet to come. Below is the prototype of the function:\n",
    "\n",
    "```basis(L, K, basis_name, dev='cpu', T0=None)```\n",
    "\n",
    "In the next, we shall see a simple example but I let you consult the documentation by typing ``help(pyfaust.poly.basis)`` to get more details.  \n",
    "\n",
    "For instance, if you want to instantiate a basis Faust of dimension K+1 (below K=5) on L, which by the way must be a ``scipy.sparse.csr_matrix`` at least square (and most likely symmetric positive definite in much use cases),  you'll make this call to the function:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d077b727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Faust size 768x128, density 0.85612, nnz_sum 84160, 6 factor(s): \n",
       "- FACTOR 0 (real) SPARSE, size 768x640, density 0.0347656, nnz 17088\n",
       "- FACTOR 1 (real) SPARSE, size 640x512, density 0.0517578, nnz 16960\n",
       "- FACTOR 2 (real) SPARSE, size 512x384, density 0.085612, nnz 16832\n",
       "- FACTOR 3 (real) SPARSE, size 384x256, density 0.169922, nnz 16704\n",
       "- FACTOR 4 (real) SPARSE, size 256x128, density 0.501953, nnz 16448\n",
       "- FACTOR 5 (real) SPARSE, size 128x128, density 0.0078125, nnz 128\n",
       " identity matrix flag"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyfaust.poly import basis\n",
    "from scipy.sparse import random\n",
    "d = 128\n",
    "L = random(d, d, .2, format='csr')\n",
    "L = L@L.T\n",
    "K=5\n",
    "F = basis(L, K=K, basis_name='chebyshev')\n",
    "F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0533a8",
   "metadata": {},
   "source": [
    "As you can see, the last factor is followed by the mention ``identity matrix flag``. It means that this factor is the identity matrix. This is not suprising, because the 0-degree Chebyshev polynomial is the identity. However, note that the ``T0`` optional argument of the function is here to trick the basis by using another matrix than the identity even if eventually it might not be a proper basis it can be useful if you want to apply this basis on a vector or a matrix (hence you'll set ``T0`` as this vector/matrix instead of multiplying the basis by this vector/matrix).  \n",
    "\n",
    "So how should we understand this Faust? You can see it as a vertical concatenation of polynomials. Indeed, the basis is composed of K+1 polynomials, the 0-degree polynomial is at the top of the stack (i.e. ``F[:d,:]`` is the identity):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95b00e50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F[:d,:].toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda9bfcc",
   "metadata": {},
   "source": [
    "This first 0-degree polynomial is followed by the next degree polynomials: hence ``F[d:d*2, :]`` is the 1-degree polynomial, ``F[d*2:d*3, :]`` is the 2-degree polynomial and so on...\n",
    "\n",
    "For details about the Chebyshev polynomials, including their definition by a recurrence relationship (that is used here behind the scene), you can look at this [page](https://en.wikipedia.org/wiki/Chebyshev_polynomials)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c4274c",
   "metadata": {},
   "source": [
    "One of the most important thing to note about a polynomial basis Faust is that the multiplication by a vector or a matrix is specialized in order to optimize the performance obtained with the generic Faust-vector/matrix multiplication. Indeed, due to the particular structure of the polynomial basis Faust, the multiplication can be optimized.\n",
    "\n",
    "Let's verify that is true! In the code below F is cloned to a classic Faust G and the time of the multiplication by a matrix is measured in the both cases (with F, the basis Faust and G its classic Faust copy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efaf2c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.96 ms ± 181 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "7.46 ms ± 100 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "G = F.clone()\n",
    "from numpy.random import rand\n",
    "X = rand(F.shape[1],100)\n",
    "%timeit F@X\n",
    "%timeit G@X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6cbefc",
   "metadata": {},
   "source": [
    "Now let's verify the multiplication result is accurate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f031472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "err= 1.239890671949257e-16\n"
     ]
    }
   ],
   "source": [
    "from numpy.linalg import norm\n",
    "print(\"err=\", norm(F@X-G@X)/norm(F@X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef58bba3",
   "metadata": {},
   "source": [
    "As you see it's alright."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2683cd",
   "metadata": {},
   "source": [
    "## 2. The poly function\n",
    "\n",
    "The second function of the ``pyfaust.poly`` module is ``poly``. This function purpose is to compute a linear combination of polynomials composing a ``FaustPoly``. So passing the ``FaustPoly`` and the coefficients (one per polynomial) for the linear combination you'll obtain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f50fe04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Faust size 128x128, density 5.18359, nnz_sum 84928, 7 factor(s): \n",
       "- FACTOR 0 (real) SPARSE, size 128x768, density 0.0078125, nnz 768\n",
       "- FACTOR 1 (real) SPARSE, size 768x640, density 0.0347656, nnz 17088\n",
       "- FACTOR 2 (real) SPARSE, size 640x512, density 0.0517578, nnz 16960\n",
       "- FACTOR 3 (real) SPARSE, size 512x384, density 0.085612, nnz 16832\n",
       "- FACTOR 4 (real) SPARSE, size 384x256, density 0.169922, nnz 16704\n",
       "- FACTOR 5 (real) SPARSE, size 256x128, density 0.501953, nnz 16448\n",
       "- FACTOR 6 (real) SPARSE, size 128x128, density 0.0078125, nnz 128\n",
       " identity matrix flag"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyfaust.poly import poly\n",
    "from numpy import array\n",
    "coeffs = array([rand()*100 for i in range(K+1)])\n",
    "lc_F = poly(coeffs, F)\n",
    "lc_F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88d2b0b",
   "metadata": {},
   "source": [
    "To be explicit about ``lc_F`` let's show how to rebuild it manually using G (which again is a classic Faust equal to F)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb13f8f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error lc_G/lc_F: 4.280382463461641e-16\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import eye\n",
    "from scipy.sparse import hstack\n",
    "from pyfaust import Faust\n",
    "Id = eye(d, format='csr')\n",
    "#coeffs_factor = hstack(tuple(coeffs[i]*Id for i in range(K+1)), format='csr')\n",
    "#lc_G = Faust(coeffs_factor)@G\n",
    "lc_G = coeffs[0]*G[:d,:]\n",
    "for i in range(1, K+1):\n",
    "    lc_G += coeffs[i]*G[d*i:d*(i+1),:]\n",
    "print(\"error lc_G/lc_F:\", (lc_F-lc_G).norm()/(lc_G).norm())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a321a8b",
   "metadata": {},
   "source": [
    "Here again the ``FaustPoly`` operation is optimized compared to the ``Faust`` one. Speaking of which, there is ways to do even more optimized because the ``poly`` function is kind of matrix type agnostic (or precisely, it accepts a ``FaustPoly`` or a ``numpy.ndarray`` as the basis argument. Doing with the latter an optimized implementation is used whose the memory footprint is smaller than the one consumed with a ``FaustPoly``. It can be particulary efficient when the use cases (as we'll see in [3.]()) that consist to apply a linear combination of F to a vector x as it's shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bf4ca1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = rand(F.shape[1])\n",
    "way1 = lambda: poly(coeffs, F)@x # first way to do as we've done above\n",
    "way2 = lambda: poly(coeffs, F@x) # second way to do (that is quicker)\n",
    "way3 = lambda: poly(coeffs, F, X=x) # third way to do (it's even quicker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a438a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127 µs ± 6.38 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit way1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "279c52d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98.3 µs ± 2.46 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit way2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a0d5e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78.3 µs ± 430 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit way3()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3319d60",
   "metadata": {},
   "source": [
    "OK! The second way to do is quicker and the third is the quickest but just in case let's verify all ways give the same results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b0c7188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "err way2 = 1.2393110086488054e-16\n"
     ]
    }
   ],
   "source": [
    "print(\"err way2 =\", norm(poly(coeffs, F)@x-poly(coeffs, F@x))/norm(poly(coeffs, F)@x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc3834b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "err way3 = 1.2393110086488054e-16\n"
     ]
    }
   ],
   "source": [
    "print(\"err way3 =\", norm(poly(coeffs, F)@x-poly(coeffs, F, X=x))/norm(poly(coeffs, F)@x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c1042a",
   "metadata": {},
   "source": [
    "All sounds good! We shall now introduce two use cases of Chebyshev polynomials in FAµST that allow to get interesting results compared to what we can do in the numpy/scipy ecosystem. But to note a last thing before going ahead to the part [3.]() is that the function poly is a little more complicated that it looks, fore more details I invite you to consult the [API documentation](https://faustgrp.gitlabpages.inria.fr/faust/last-doc/html/namespacepyfaust.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66108e8",
   "metadata": {},
   "source": [
    "## 3. Computing the action of the inverse / exponential of a matrix on a vector\n",
    "\n",
    "Computing the action of the inverse of a matrix A on a vector x means to compute $y = A^{-1} x$ without actually computing the inverse of A.\n",
    "That's exactly what the function ``pyfaust.poly.invm_multiply`` is able to do using ``FaustPoly`` behind the scene. Let's generate a random sparse matrix (because that's the interesting use case) and compute $y$ using ``invm_multiply`` besides to computing the inverse in order to measure the relative performance and accurracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6fd97c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.1 ms ± 563 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "154 ms ± 1.1 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "465 µs ± 50.9 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "from pyfaust.poly import invm_multiply\n",
    "from scipy.sparse.linalg import inv\n",
    "from numpy.linalg import inv as numpy_inv\n",
    "from scipy.sparse import csc_matrix\n",
    "import numpy as np\n",
    "S = random(d, d, .05, format='csr')\n",
    "x = rand(d, 1)\n",
    "A = S@S.T # invm_multiply is only able to treat a symmetric positive definite matrix, that's its limitation!\n",
    "cscA = csc_matrix(A) # scipy prefers CSC to invert a matrix (for efficiency)\n",
    "max_K = np.inf\n",
    "rel_err=1e-3\n",
    "full_A = A.toarray()\n",
    "%timeit inv(cscA)@x\n",
    "%timeit invm_multiply(A, x, tradeoff='time', rel_err=rel_err, max_K=max_K)\n",
    "%timeit numpy_inv(full_A)@x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101f2a3a",
   "metadata": {},
   "source": [
    "Now that we've seen that ``invm_multiply`` works quicker, as usual we check below that it's accurate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e94a7186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "err: 0.8689511053955197\n"
     ]
    }
   ],
   "source": [
    "y1 = inv(cscA)@x\n",
    "y2 =  invm_multiply(A, x, tradeoff='time', rel_err=rel_err, max_K=max_K)\n",
    "print(\"err:\", norm(y2-y1)/norm(y1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5be836",
   "metadata": {},
   "source": [
    "There are function arguments to govern the precision and computation time tradeoff (the most important argument being 'tradeoff' itself, which takes the 'memory' or 'time' depending on your primary criterion). You'll find them in the [API documentation](https://faustgrp.gitlabpages.inria.fr/faust/last-doc/html/namespacepyfaust.html).\n",
    "\n",
    "In the next, we'll see how to compute action of the exponential matrix on a vector x. However this time we'll do the comparison with the scipy function [``scipy.sparse.linalg.expm_multiply``](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.expm_multiply.html).\n",
    "The both functions are intended to compute the action of the exponential matrix on a vector or matrix. Recalling that it consists to compute $exp(t A)x$ without computing directly the exponential let's compare the use, performance and accuracy of these functions.  \n",
    "The main difference between the two of them, is that in pyfaust the time points are passed directly as a list to the function, while the scipy version accepts only on ``np.linspace`` style arguments (to define the points as a regular space)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82c7c82d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pyfaust error: 7.65649062956808e-11\n",
      "130 ms ± 1.74 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "1.2 s ± 28.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse.linalg import expm_multiply as scipy_expm_multiply\n",
    "from pyfaust.poly import expm_multiply\n",
    "from numpy import exp, linspace\n",
    "from numpy.linalg import norm\n",
    "from numpy.random import rand\n",
    "from scipy.sparse import random\n",
    "S = random(1024, 1024, .002, format='csr')\n",
    "A = S@S.T\n",
    "X = rand(A.shape[1], 1)\n",
    "pts_args = {'start':-.5, 'stop':-.2, 'num':1000}\n",
    "pts = linspace(**pts_args)\n",
    "y1 = expm_multiply(A, X, pts)\n",
    "y2 = scipy_expm_multiply(A, X, **pts_args)\n",
    "print(\"pyfaust error:\", norm(y1-y2)/norm(y2))\n",
    "%timeit expm_multiply(A, X, pts)\n",
    "%timeit scipy_expm_multiply(A, X, **pts_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4312be4",
   "metadata": {},
   "source": [
    "It is rather good for ``pyfaust`` but note that there is some drawbacks to its expm_multiply implementation. You'll find them among other details in the [API documentation](https://faustgrp.gitlabpages.inria.fr/faust/last-doc/html/namespacepyfaust.html)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
